import joblib
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import os


class ModelPredictor:
    def __init__(self, model_path, data_path, target_col):
        self.model_path = model_path
        self.data_path = data_path
        self.target_col = target_col
        self.model = None

    def load_model(self):
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: –í –º–µ—Ç–æ–¥–µ load_model –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é joblib.load().
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        print(f"[+] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}...")
        self.model = joblib.load(self.model_path)
        print("[+] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

    def load_data(self):
        # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("[+] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
        df = pd.read_parquet(self.data_path)
        print(f"[+] –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {df.shape}")
        return df

    def preprocess(self, df):
        # –í –º–µ—Ç–æ–¥–µ preprocess –º—ã –≤—ã–ø–æ–ª–Ω—è–µ–º —Ç–µ –∂–µ —à–∞–≥–∏, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏:
        # —É–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é.
        print("[+] –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

        # –£–¥–∞–ª—è–µ–º 'datetime', –µ—Å–ª–∏ –µ—Å—Ç—å
        if 'datetime' in df.columns:
            df = df.drop(columns=['datetime'])

        # –û—Ç–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        X = df.drop(columns=[self.target_col])
        y = df[self.target_col].astype(int)

        print("[+] Target distribution:")
        print(y.value_counts(normalize=True))

        return X, y

    def predict(self, X):
        # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –º–æ–¥–µ–ª–∏
        print("[+] –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
        y_pred = self.model.predict(X)
        return y_pred

    def evaluate(self, y_true, y_pred):
        # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        print("[+] üìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")

        print("[+] Classification Report:")
        print(classification_report(y_true, y_pred, digits=2))

        print("[+] Confusion Matrix:")
        cm = confusion_matrix(y_true, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        plt.title("Confusion Matrix")
        plt.show()

    def save_predictions(self, y_pred):
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ CSV
        os.makedirs('predictions', exist_ok=True)
        predictions_df = pd.DataFrame(y_pred, columns=['prediction'])
        predictions_df.to_csv('predictions/predictions.csv', index=False)
        print("[+] –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ predictions/predictions.csv")

    def run(self):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        self.load_model()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = self.load_data()

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X, y = self.preprocess(df)

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = self.predict(X)

        # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
        self.evaluate(y, y_pred)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.save_predictions(y_pred)


